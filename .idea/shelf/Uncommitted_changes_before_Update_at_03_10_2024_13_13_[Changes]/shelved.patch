Index: requirements.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#\r\n# This file is autogenerated by pip-compile with Python 3.12\r\n# by the following command:\r\n#\r\n#    pip-compile --no-emit-options --output-file=requirements.txt pyproject.toml\r\n#\r\nannotated-types==0.6.0\r\n    # via pydantic\r\nanyio==3.7.1\r\n    # via\r\n    #   fastapi\r\n    #   starlette\r\nbcrypt==4.1.2\r\n    # via fastapi-nano (pyproject.toml)\r\ncffi==1.16.0\r\n    # via cryptography\r\nclick==8.1.7\r\n    # via uvicorn\r\ncryptography==41.0.7\r\n    # via python-jose\r\necdsa==0.18.0\r\n    # via python-jose\r\nfastapi==0.104.0\r\n    # via fastapi-nano (pyproject.toml)\r\ngunicorn==21.2.0\r\n    # via fastapi-nano (pyproject.toml)\r\nh11==0.14.0\r\n    # via uvicorn\r\nidna==3.4\r\n    # via anyio\r\npackaging==23.2\r\n    # via gunicorn\r\npasslib==1.7.4\r\n    # via fastapi-nano (pyproject.toml)\r\npyasn1==0.5.0\r\n    # via\r\n    #   python-jose\r\n    #   rsa\r\npycparser==2.21\r\n    # via cffi\r\npydantic==2.4.2\r\n    # via fastapi\r\npydantic-core==2.10.1\r\n    # via pydantic\r\npython-jose[cryptography]==3.3.0\r\n    # via fastapi-nano (pyproject.toml)\r\npython-multipart==0.0.6\r\n    # via fastapi-nano (pyproject.toml)\r\nrsa==4.9\r\n    # via python-jose\r\nsix==1.16.0\r\n    # via ecdsa\r\nsniffio==1.3.0\r\n    # via anyio\r\nstarlette==0.27.0\r\n    # via fastapi\r\ntyping-extensions==4.8.0\r\n    # via\r\n    #   fastapi\r\n    #   pydantic\r\n    #   pydantic-core\r\nuvicorn==0.27.0.post1\r\n    # via fastapi-nano (pyproject.toml)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/requirements.txt b/requirements.txt
--- a/requirements.txt	(revision c06e1f6afdb5a3cce83b97029b24eb80bc4be5b2)
+++ b/requirements.txt	(date 1727875952690)
@@ -4,60 +4,15 @@
 #
 #    pip-compile --no-emit-options --output-file=requirements.txt pyproject.toml
 #
-annotated-types==0.6.0
-    # via pydantic
-anyio==3.7.1
-    # via
-    #   fastapi
-    #   starlette
-bcrypt==4.1.2
-    # via fastapi-nano (pyproject.toml)
-cffi==1.16.0
-    # via cryptography
-click==8.1.7
-    # via uvicorn
-cryptography==41.0.7
-    # via python-jose
-ecdsa==0.18.0
-    # via python-jose
-fastapi==0.104.0
-    # via fastapi-nano (pyproject.toml)
-gunicorn==21.2.0
-    # via fastapi-nano (pyproject.toml)
-h11==0.14.0
-    # via uvicorn
-idna==3.4
-    # via anyio
-packaging==23.2
-    # via gunicorn
-passlib==1.7.4
-    # via fastapi-nano (pyproject.toml)
-pyasn1==0.5.0
-    # via
-    #   python-jose
-    #   rsa
-pycparser==2.21
-    # via cffi
-pydantic==2.4.2
-    # via fastapi
-pydantic-core==2.10.1
-    # via pydantic
-python-jose[cryptography]==3.3.0
-    # via fastapi-nano (pyproject.toml)
-python-multipart==0.0.6
-    # via fastapi-nano (pyproject.toml)
-rsa==4.9
-    # via python-jose
-six==1.16.0
-    # via ecdsa
-sniffio==1.3.0
-    # via anyio
-starlette==0.27.0
-    # via fastapi
-typing-extensions==4.8.0
-    # via
-    #   fastapi
-    #   pydantic
-    #   pydantic-core
-uvicorn==0.27.0.post1
-    # via fastapi-nano (pyproject.toml)
+fastapi
+pydantic
+python-jose[cryptography]
+starlette
+ldap3
+pytest
+requests
+PyMuPDF
+python-docx
+thefuzz
+validators
+openai
\ No newline at end of file
Index: .idea/vcs.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/vcs.xml b/.idea/vcs.xml
new file mode 100644
--- /dev/null	(date 1727274620057)
+++ b/.idea/vcs.xml	(date 1727274620057)
@@ -0,0 +1,6 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project version="4">
+  <component name="VcsDirectoryMappings">
+    <mapping directory="" vcs="Git" />
+  </component>
+</project>
\ No newline at end of file
Index: app/core/auth.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom datetime import datetime, timedelta\r\nfrom http import HTTPStatus\r\n\r\nfrom fastapi import APIRouter, Depends, HTTPException\r\nfrom fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm\r\nfrom jose import JWTError, jwt\r\nfrom passlib.context import CryptContext\r\nfrom pydantic import BaseModel\r\n\r\nfrom app.core import config\r\n\r\n\r\nclass Token(BaseModel):\r\n    access_token: str\r\n    token_type: str\r\n\r\n\r\nclass TokenData(BaseModel):\r\n    username: str | None = None\r\n\r\n\r\nclass User(BaseModel):\r\n    username: str\r\n    disabled: bool = False\r\n\r\n\r\nclass UserInDB(User):\r\n    hashed_password: str\r\n\r\n\r\npwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\r\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"/token\")\r\nrouter = APIRouter()\r\n\r\n\r\ndef verify_password(plain_password: str, hashed_password: str) -> bool:\r\n    return pwd_context.verify(plain_password, hashed_password)\r\n\r\n\r\ndef get_password_hash(password: str) -> str:\r\n    return pwd_context.hash(password)\r\n\r\n\r\nfake_users_db = {\r\n    \"ubuntu\": {\r\n        \"username\": config.API_USERNAME,\r\n        \"hashed_password\": get_password_hash(config.API_PASSWORD),\r\n    }\r\n}\r\n\r\n\r\ndef get_user(db: dict[str, dict[str, dict]], username: str | None) -> UserInDB | None:\r\n    if username not in db:\r\n        return None\r\n    user_dict = db[username]\r\n    return UserInDB(**user_dict)\r\n\r\n\r\ndef authenticate_user(\r\n    fake_db: dict[str, dict[str, dict]],\r\n    username: str,\r\n    password: str,\r\n) -> bool | UserInDB:\r\n    user = get_user(fake_db, username)\r\n    if not user:\r\n        return False\r\n    if not verify_password(password, user.hashed_password):\r\n        return False\r\n    return user\r\n\r\n\r\ndef create_access_token(data: dict, expires_delta: timedelta | None = None) -> str:\r\n    to_encode = data.copy()\r\n\r\n    if expires_delta:\r\n        expire = datetime.utcnow() + expires_delta\r\n    else:\r\n        expire = datetime.utcnow() + timedelta(minutes=15)\r\n\r\n    to_encode.update({\"exp\": expire})\r\n    encoded_jwt = jwt.encode(\r\n        to_encode,\r\n        config.API_SECRET_KEY,\r\n        algorithm=config.API_ALGORITHM,\r\n    )\r\n    return encoded_jwt\r\n\r\n\r\ndef get_current_user(token: str = Depends(oauth2_scheme)) -> UserInDB:\r\n    credentials_exception = HTTPException(\r\n        status_code=HTTPStatus.UNAUTHORIZED,\r\n        detail=\"Could not validate credentials\",\r\n        headers={\"WWW-Authenticate\": \"Bearer\"},\r\n    )\r\n\r\n    try:\r\n        payload = jwt.decode(\r\n            token,\r\n            config.API_SECRET_KEY,\r\n            algorithms=[config.API_ALGORITHM],\r\n        )\r\n        username = payload.get(\"sub\")\r\n\r\n        if username is None:\r\n            raise credentials_exception\r\n        token_data = TokenData(username=username)\r\n\r\n    except JWTError:\r\n        raise credentials_exception\r\n\r\n    user = get_user(fake_users_db, username=token_data.username)\r\n\r\n    if user is None:\r\n        raise credentials_exception\r\n    return user\r\n\r\n\r\n@router.post(\"/token\", response_model=Token)\r\nasync def login_for_access_token(\r\n    form_data: OAuth2PasswordRequestForm = Depends(),\r\n) -> dict[str, str]:\r\n    user = authenticate_user(\r\n        fake_users_db,\r\n        form_data.username,\r\n        form_data.password,\r\n    )\r\n\r\n    if not user:\r\n        raise HTTPException(\r\n            status_code=HTTPStatus.UNAUTHORIZED,\r\n            detail=\"Incorrect username or password\",\r\n            headers={\"WWW-Authenticate\": \"Bearer\"},\r\n        )\r\n\r\n    access_token_expires = timedelta(\r\n        seconds=config.API_ACCESS_TOKEN_EXPIRE_MINUTES,\r\n    )\r\n    access_token = create_access_token(\r\n        data={\"sub\": user.username},  # type: ignore\r\n        expires_delta=access_token_expires,\r\n    )\r\n    return {\"access_token\": access_token, \"token_type\": \"bearer\"}\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/core/auth.py b/app/core/auth.py
--- a/app/core/auth.py	(revision c06e1f6afdb5a3cce83b97029b24eb80bc4be5b2)
+++ b/app/core/auth.py	(date 1727692463449)
@@ -3,73 +3,50 @@
 from datetime import datetime, timedelta
 from http import HTTPStatus
 
-from fastapi import APIRouter, Depends, HTTPException
-from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
+from fastapi import APIRouter, HTTPException
 from jose import JWTError, jwt
-from passlib.context import CryptContext
-from pydantic import BaseModel
+from pydantic import BaseModel, SecretStr
+
+from ldap3 import Server, Connection
 
 from app.core import config
 
+from haystack_integrations.document_stores.elasticsearch import ElasticsearchDocumentStore
 
 class Token(BaseModel):
     access_token: str
-    token_type: str
-
-
-class TokenData(BaseModel):
-    username: str | None = None
-
+    project_name: str
 
-class User(BaseModel):
-    username: str
-    disabled: bool = False
-
-
-class UserInDB(User):
-    hashed_password: str
-
-
-pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
-oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/token")
 router = APIRouter()
 
 
-def verify_password(plain_password: str, hashed_password: str) -> bool:
-    return pwd_context.verify(plain_password, hashed_password)
-
-
-def get_password_hash(password: str) -> str:
-    return pwd_context.hash(password)
-
-
-fake_users_db = {
-    "ubuntu": {
-        "username": config.API_USERNAME,
-        "hashed_password": get_password_hash(config.API_PASSWORD),
-    }
-}
-
-
-def get_user(db: dict[str, dict[str, dict]], username: str | None) -> UserInDB | None:
-    if username not in db:
-        return None
-    user_dict = db[username]
-    return UserInDB(**user_dict)
-
-
 def authenticate_user(
-    fake_db: dict[str, dict[str, dict]],
     username: str,
     password: str,
-) -> bool | UserInDB:
-    user = get_user(fake_db, username)
-    if not user:
-        return False
-    if not verify_password(password, user.hashed_password):
-        return False
-    return user
+) -> bool:
+    dc_ldap = config.LDAP_dc.split(",")
+    username_mod = f'uid={username},ou={config.LDAP_ou},dc={dc_ldap[0]},dc={dc_ldap[1]}'
+    server = Server(config.LDAP_server, use_ssl=False, get_info='ALL')
+    # print("server",username_mod)
+    conn = Connection(server, username_mod, password, auto_bind=False, auto_referrals=False, raise_exceptions=False)
+    result = False
+    try:
+        conn.bind()
+        conn.password = None
+        if conn.result['result'] != 0:
+            result = False
+        else:
+            result = True
+    except Exception as e:
+        print(str(e).replace(config.LDAP_server, 'server'))
+    finally:
+        if conn.bound:
+            conn.unbind()
 
+    return result
+
+def authenticate_superuser(username: str, password: str,) -> bool:
+    return username == config.API_USERNAME and password == config.API_PASSWORD
 
 def create_access_token(data: dict, expires_delta: timedelta | None = None) -> str:
     to_encode = data.copy()
@@ -88,11 +65,11 @@
     return encoded_jwt
 
 
-def get_current_user(token: str = Depends(oauth2_scheme)) -> UserInDB:
+def decode_access_token(token: str) -> str:
     credentials_exception = HTTPException(
         status_code=HTTPStatus.UNAUTHORIZED,
         detail="Could not validate credentials",
-        headers={"WWW-Authenticate": "Bearer"},
+        #headers={"WWW-Authenticate": "Bearer"},
     )
 
     try:
@@ -101,44 +78,100 @@
             config.API_SECRET_KEY,
             algorithms=[config.API_ALGORITHM],
         )
-        username = payload.get("sub")
-
-        if username is None:
+        content = payload.get("sub")
+        if content is None:
             raise credentials_exception
-        token_data = TokenData(username=username)
-
     except JWTError:
         raise credentials_exception
 
-    user = get_user(fake_users_db, username=token_data.username)
-
-    if user is None:
-        raise credentials_exception
-    return user
+    return content
 
+@router.post("/list", tags=["projects"])
+async def list_projects(username:str, password:SecretStr) -> list:
+    """ Show info about user projects """
+    username = username.lower().strip()
+    query_settings = {'query': {'match': {'user': username}}}
+    isSuperuser =False
 
-@router.post("/token", response_model=Token)
-async def login_for_access_token(
-    form_data: OAuth2PasswordRequestForm = Depends(),
-) -> dict[str, str]:
-    user = authenticate_user(
-        fake_users_db,
-        form_data.username,
-        form_data.password,
+    if authenticate_superuser(username,password.get_secret_value().strip()) :
+        isSuperuser = True
+
+    elif not authenticate_user(username, password.get_secret_value().strip()):
+        raise HTTPException(
+            status_code=HTTPStatus.UNAUTHORIZED,
+            detail="Incorrect username or password",
+        )
+    access_token_expires = timedelta(
+        seconds=config.API_ACCESS_TOKEN_EXPIRE_MINUTES,
     )
+    if isSuperuser or username in list(config.ADMIN_USERS):
+        query_settings = None
+        isSuperuser = True
 
-    if not user:
+    document_store = ElasticsearchDocumentStore(hosts=config.DB_HOST, index=config.PROJECTS_INDEX,
+                                                custom_mapping=config.INDEX_SETTINGS)
+    response = document_store.client.search(index=config.PROJECTS_INDEX, body=query_settings)
+    result = []
+    # print("Total:", response['hits']['total']['value'])
+    # print(response['hits']['max_score'])
+    # for hit in response['hits']['hits']:
+    #    print(hit['_source'])
+    for hit in response['hits']['hits']:
+        access_token = create_access_token(
+            data={"sub": hit['_source']['name']},  # type: ignore
+            expires_delta=access_token_expires,
+        )
+        item = {"project": hit['_source']['name'], "description": hit['_source']['description'], "token": access_token}
+        if isSuperuser:
+            item.update({"user":hit['_source']['user']})
+        result.append(item)
+    document_store.client.close()
+    return result
+
+@router.post("/create", response_model=Token, tags=["projects"])
+async def create_project(username:str, password:SecretStr, project_name:str, project_description:str ="",) -> dict[str, str]:
+    """
+        Create a new project and return the access token
+    """
+    username = username.lower().strip()
+    if not authenticate_user(
+        username, password.get_secret_value()
+    ):
         raise HTTPException(
             status_code=HTTPStatus.UNAUTHORIZED,
             detail="Incorrect username or password",
-            headers={"WWW-Authenticate": "Bearer"},
+            #headers={"WWW-Authenticate": "Bearer"},
         )
-
+    project_name = project_name.strip().lower().replace(" ", "_")
     access_token_expires = timedelta(
         seconds=config.API_ACCESS_TOKEN_EXPIRE_MINUTES,
     )
     access_token = create_access_token(
-        data={"sub": user.username},  # type: ignore
+        data={"sub": project_name},  # type: ignore
         expires_delta=access_token_expires,
     )
-    return {"access_token": access_token, "token_type": "bearer"}
+
+    #Create project index in db if not exists
+    document_store = ElasticsearchDocumentStore(hosts=config.DB_HOST, index=config.PROJECTS_INDEX, custom_mapping=config.INDEX_SETTINGS)
+    #check if previous project exits in project index
+    response = document_store.client.search(index=config.PROJECTS_INDEX, body={'query': {'match': {'name': project_name}}})
+    if  response['hits']['total']['value'] == 0:
+        #if exists, add new project to project index
+        document_store.client.index(index=config.PROJECTS_INDEX, body={"project": project_name, "description": project_description, "user": username})
+        document_store.client.close()
+        #create new index
+        document_store = ElasticsearchDocumentStore(hosts=config.DB_HOST, index=project_name)   #Create the new index
+        document_store.client.close()
+    else:
+        # print("Total:", response['hits']['total']['value'])
+        #print(response['hits']['max_score'])
+        #for hit in response['hits']['hits']:
+        #    print(hit['_source'])
+        document_store.client.close()
+        raise HTTPException(
+            status_code=HTTPStatus.UNPROCESSABLE_ENTITY,
+            detail="Project name already exists!",
+            #     #headers={"WWW-Authenticate": "Bearer"},
+        )
+
+    return {"access_token": access_token, "project_name": project_name}
\ No newline at end of file
Index: app/apis/api_documents/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/apis/api_documents/utils.py b/app/apis/api_documents/utils.py
new file mode 100644
--- /dev/null	(date 1727790032123)
+++ b/app/apis/api_documents/utils.py	(date 1727790032123)
@@ -0,0 +1,70 @@
+from __future__ import annotations
+
+import requests
+from haystack_integrations.components.retrievers.elasticsearch import ElasticsearchBM25Retriever, \
+    ElasticsearchEmbeddingRetriever
+from haystack_integrations.document_stores.elasticsearch import ElasticsearchDocumentStore
+
+from app.core.config import EMBEDDINGS_SERVER, EMBEDDINGS_MODEL
+
+def searchInDocstore(params, document_store:ElasticsearchDocumentStore):
+    """
+    Search documents in database
+    """
+    count = params.query.strip().count(" ")+ 1
+    prediction = None
+    if  count < 3:
+        #print("BM25 method")
+        bm25retriever = ElasticsearchBM25Retriever(document_store=document_store, scale_score=True)
+        prediction = bm25retriever.run(query=params.query.strip(),top_k=params.top_k, filters=params.filters)["documents"]
+        #prediction = document_store.bm25_retrieval(query=params.query.strip(), top_k=params.top_k, filters=params.filters, scale_score=True)
+        for doc in prediction:
+           del doc.embedding
+    else:
+        myquery=get_detailed_instruct(params.query.strip())
+        #embedding_query = text_embedder.run(text=myquery)["embedding"]
+        #embedding_query = model.encode(myquery, normalize_embeddings=True, show_progress_bar=True, device="cuda", batch_size=4)
+        try:
+            req = requests.post(EMBEDDINGS_SERVER+"embeddings", json={"input": myquery,"model": EMBEDDINGS_MODEL})    #encode query
+            if req.status_code == 200:
+                query_embedding = req.json()["data"][0]["embedding"]
+                #prediction = document_store.embedding_retrieval(query_embedding=query_embedding, top_k=params.top_k, filters=params.filters, return_embedding=False)
+                retriever = ElasticsearchEmbeddingRetriever(document_store=document_store)
+                prediction = retriever.run(query_embedding=query_embedding, top_k=params.top_k, filters=params.filters)["documents"]
+                for doc in prediction:
+                   del doc.embedding
+        except requests.exceptions.RequestException as e:
+            return None
+    #print_documents(prediction, max_text_len=query.max_text_len, print_name=True, print_meta=True)
+    return prediction
+
+
+def get_detailed_instruct(query: str) -> str:
+    ''' Necessary with model intfloat/multilingual-e5-large-instruct '''
+    task_description = 'Given a web search query, retrieve relevant passages that answer the query'
+    return f'Instruct: {task_description}\nQuery: {query}'
+
+
+def getContext(docs:list, context_size:int, document_store:ElasticsearchDocumentStore) -> list:
+    if context_size > 0:
+        for doc in docs:
+            currentParagraph = doc["paragraph"]
+            min_paragrah = currentParagraph - context_size
+            if min_paragrah < 0:
+                min_paragrah = 0
+            min_paragrah = list(range(min_paragrah, currentParagraph))
+            max_paragraph = list(range(currentParagraph + 1, currentParagraph + context_size + 1))
+            context_list = min_paragrah + max_paragraph
+            current_filters = {"operator": "AND",
+                               "conditions": [{"field": "name", "operator": "==", "value": doc["name"]},
+                                              {"field": "paragraph", "operator": "in", "value": context_list}, ]}
+            getDocuments = document_store.filter_documents(filters=current_filters)
+            doc["before_context"] = []
+            doc["after_context"] = []
+            for context in getDocuments:
+                if context.meta["paragraph"] < currentParagraph:
+                    doc["before_context"].append(context.content)
+                else:
+                    doc["after_context"].append(context.content)
+
+    return docs
\ No newline at end of file
Index: .idea/.gitignore
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/.gitignore b/.idea/.gitignore
new file mode 100644
--- /dev/null	(date 1727274620187)
+++ b/.idea/.gitignore	(date 1727274620187)
@@ -0,0 +1,3 @@
+# Default ignored files
+/shelf/
+/workspace.xml
Index: app/apis/api_llm/llm_utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/apis/api_llm/llm_utils.py b/app/apis/api_llm/llm_utils.py
new file mode 100644
--- /dev/null	(date 1727879738955)
+++ b/app/apis/api_llm/llm_utils.py	(date 1727879738955)
@@ -0,0 +1,59 @@
+from __future__ import annotations
+
+TEMPLATE_ASK="""   
+Se proporciona información procedente de cada documento:
+
+    {% for name, content in myDocs.items() %}
+        Documento: {{ name }}        
+        {% for text in content %}
+            - {{text}}
+
+        {% endfor %}   
+    {% endfor %}
+
+    Por cada uno de los documentos proporcionados, responde en el mismo idioma a la siguiente pregunta: {{ query }}. No te inventes nada.
+"""
+
+TEMPLATE_SUMMARY = """
+Haz un resumen conciso y claro que capture los puntos más importantes del siguiente contexto. No te inventes nada. Responde solo con el resumen. Si no puedes hacerlo, no pongas nada.
+Contexto:
+{{myDocs}}
+
+Resumen:
+"""
+
+TEMPLATE_TRANSLATE = """
+La siguiente lista contiene textos:
+
+{{srt_file}}
+
+Responde con una lista con cada texto traducido al idioma {{lang}}, en el mismo orden y con igual formato que la lista original. No te inventes nada.
+
+Ejemplo respuesta:
+
+1- Hello world.
+
+2- A long sentence to translate.
+
+"""
+
+# def launchAgent(prompt:str, options:dict):
+#     try:
+#         #req = requests.post(OLLAMA_SERVER+"api/generate", json={"model":LLM_MODEL,"prompt":prompt, "system":"Eres un asistente muy obediente.","keep_alive":-1, "stream":False, "options": options})
+#         #req = requests.post(OLLAMA_SERVER+"api/generate", json={"model":LLM_MODEL,"prompt":prompt, "keep_alive":-1, "stream":False, "options": options})
+#         client = OpenAI(
+#             base_url=OLLAMA_SERVER+'v1/',
+#
+#             # required but ignored
+#             api_key='ollama',
+#         )
+#         completion = client.completions.create(
+#             model=LLM_MODEL,
+#             prompt="Say this is a test",
+#         )
+#         #req.raise_for_status()
+#         #return req.json()["response"]
+#         completion
+#
+#     except requests.exceptions.RequestException as e:
+#         return None
Index: app/tests/test_apis.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from http import HTTPStatus\r\n\r\nimport pytest\r\nfrom fastapi.testclient import TestClient\r\n\r\nfrom app.core import config\r\nfrom app.main import app\r\n\r\nclient = TestClient(app)\r\n\r\n\r\n@pytest.fixture(scope=\"module\")\r\ndef api_token():\r\n    # Get token.\r\n    res = client.post(\r\n        \"/token\",\r\n        headers={\"Accept\": \"application/x-www-form-urlencoded\"},\r\n        data={\r\n            \"username\": config.API_USERNAME,\r\n            \"password\": config.API_PASSWORD,\r\n        },\r\n    )\r\n    res_json = res.json()\r\n\r\n    access_token = res_json[\"access_token\"]\r\n    token_type = res_json[\"token_type\"]\r\n\r\n    return f\"{token_type} {access_token}\"\r\n\r\n\r\ndef test_api_a_unauthorized():\r\n    \"\"\"Should return 401.\"\"\"\r\n\r\n    # Unauthorized request.\r\n    response = client.get(\"/api_a/100\")\r\n    assert response.status_code == HTTPStatus.UNAUTHORIZED\r\n\r\n\r\ndef test_api_a_invalid_input(api_token):\r\n    \"\"\"Should return 422.\"\"\"\r\n\r\n    # Authorized but should raise 400 error.\r\n    response = client.get(\r\n        \"/api_a/a\",\r\n        headers={\r\n            \"Accept\": \"application/json\",\r\n            \"Authorization\": api_token,\r\n        },\r\n    )\r\n    assert response.status_code == HTTPStatus.UNPROCESSABLE_ENTITY\r\n\r\n\r\ndef test_api_a_ok(api_token):\r\n    # Successful request.\r\n    response = client.get(\r\n        \"/api_a/200\",\r\n        headers={\r\n            \"Accept\": \"application/json\",\r\n            \"Authorization\": api_token,\r\n        },\r\n    )\r\n    assert response.status_code == HTTPStatus.OK\r\n\r\n    for val in response.json().values():\r\n        assert isinstance(val, int)\r\n\r\n\r\ndef test_api_b_unauthorized():\r\n    \"\"\"Should return 401.\"\"\"\r\n\r\n    # Unauthorized request.\r\n    response = client.get(\"/api_b/200\")\r\n    assert response.status_code == HTTPStatus.UNAUTHORIZED\r\n\r\n\r\ndef test_api_b_invalid_input(api_token):\r\n    \"\"\"Should return 422.\"\"\"\r\n\r\n    # Authorized but should raise 400 error.\r\n    response = client.get(\r\n        \"/api_b/b\",\r\n        headers={\r\n            \"Accept\": \"application/json\",\r\n            \"Authorization\": api_token,\r\n        },\r\n    )\r\n    assert response.status_code == HTTPStatus.UNPROCESSABLE_ENTITY\r\n\r\n\r\ndef test_api_b_ok(api_token):\r\n    # Successful request.\r\n    response = client.get(\r\n        \"/api_b/300\",\r\n        headers={\r\n            \"Accept\": \"application/json\",\r\n            \"Authorization\": api_token,\r\n        },\r\n    )\r\n    assert response.status_code == HTTPStatus.OK\r\n\r\n    for val in response.json().values():\r\n        assert isinstance(val, int)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/tests/test_apis.py b/app/tests/test_apis.py
--- a/app/tests/test_apis.py	(revision c06e1f6afdb5a3cce83b97029b24eb80bc4be5b2)
+++ b/app/tests/test_apis.py	(date 1727789803011)
@@ -32,7 +32,7 @@
     """Should return 401."""
 
     # Unauthorized request.
-    response = client.get("/api_a/100")
+    response = client.get("/api_documents/100")
     assert response.status_code == HTTPStatus.UNAUTHORIZED
 
 
@@ -41,7 +41,7 @@
 
     # Authorized but should raise 400 error.
     response = client.get(
-        "/api_a/a",
+        "/api_documents/a",
         headers={
             "Accept": "application/json",
             "Authorization": api_token,
@@ -53,7 +53,7 @@
 def test_api_a_ok(api_token):
     # Successful request.
     response = client.get(
-        "/api_a/200",
+        "/api_documents/200",
         headers={
             "Accept": "application/json",
             "Authorization": api_token,
@@ -69,7 +69,7 @@
     """Should return 401."""
 
     # Unauthorized request.
-    response = client.get("/api_b/200")
+    response = client.get("/api_llm/200")
     assert response.status_code == HTTPStatus.UNAUTHORIZED
 
 
@@ -78,7 +78,7 @@
 
     # Authorized but should raise 400 error.
     response = client.get(
-        "/api_b/b",
+        "/api_llm/b",
         headers={
             "Accept": "application/json",
             "Authorization": api_token,
@@ -90,7 +90,7 @@
 def test_api_b_ok(api_token):
     # Successful request.
     response = client.get(
-        "/api_b/300",
+        "/api_llm/300",
         headers={
             "Accept": "application/json",
             "Authorization": api_token,
Index: README.md
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><div align=\"center\">\r\n\r\n![logo](https://user-images.githubusercontent.com/30027932/134270064-baecfbec-b3e7-4cb7-a07e-c11a58526260.png)\r\n\r\n[![Mentioned in Awesome <INSERT LIST NAME>](https://awesome.re/mentioned-badge-flat.svg)](https://github.com/mjhea0/awesome-fastapi#boilerplate)\r\n[![License](https://img.shields.io/cocoapods/l/AFNetworking?style=flat-square)](https://github.com/rednafi/think-asyncio/blob/master/LICENSE)\r\n[![Twitter](https://img.shields.io/twitter/follow/rednafi?style=flat-square)](https://twitter.com/rednafi)\r\n\r\n</div>\r\n\r\n## Description\r\n\r\nThis is a minimalistic and extensible [FastAPI][fastapi] template that incorporates\r\ndivisional pattern architecture with [divisional folder structure][divisional_pattern]. It's\r\nsuitable for developing small to medium sized API oriented micro-services. The architecture\r\nis similar to what you'd get with Flask's [Blueprint][blueprint].\r\n\r\n## Features\r\n\r\n-   It uses [FastAPI][fastapi] framework for API development. FastAPI is a modern, highly\r\n    performant, web framework for building APIs with Python 3.6+.\r\n\r\n-   The APIs are served with [Gunicorn](gunicorn) server with multiple [Uvicorn][uvicorn]\r\n    workers. Uvicorn is a lightning-fast \"ASGI\" server. It runs asynchronous Python web code\r\n    in a single process.\r\n\r\n-   Simple reverse-proxying with [Caddy][caddy].\r\n\r\n-   OAuth2 (with hashed password and Bearer with JWT) based authentication\r\n\r\n-   [CORS (Cross Origin Resource Sharing)][cors] enabled.\r\n\r\n-   Flask inspired divisional folder structure for better decoupling and encapsulation. This\r\n    is suitable for small to medium backend development.\r\n\r\n-   Dockerized using **python:3.12-slim-bookworm** and optimized for size and functionality.\r\n    Dockerfile for Python 3.11 and 3.10 can also be found in the `dockerfiles` directory.\r\n\r\n## Quickstart\r\n\r\n### Run the app in containers\r\n\r\n-   Clone the repo and navigate to the root folder.\r\n\r\n-   To run the app using Docker, make sure you've got [Docker][docker] installed on your\r\n    system. From the project's root directory, run:\r\n\r\n    ```sh\r\n    docker compose up -d\r\n    ```\r\n\r\n### Or, run the app locally\r\n\r\nIf you want to run the app locally, without using Docker, then:\r\n\r\n-   Clone the repo and navigate to the root folder.\r\n\r\n-   Create a virtual environment. Here I'm using Python's built-in venv in a Unix system.\r\n    Run:\r\n\r\n    ```sh\r\n    python3.12 -m venv .venv\r\n    ```\r\n\r\n-   Activate the environment. Run:\r\n\r\n    ```sh\r\n    source .venv/bin/activate\r\n    ```\r\n\r\n-   Go to the folder created by cookie-cutter (default is **fastapi-nano**).\r\n\r\n-   Install the dependencies. Run:\r\n\r\n    ```bash\r\n    pip install -r requirements.txt -r requirements-dev.txt\r\n    ```\r\n\r\n-   Start the app. Run:\r\n\r\n    ```bash\r\n    uvicorn app.main:app --port 5002 --reload\r\n    ```\r\n\r\n### Check the APIs\r\n\r\n-   To play around with the APIs, go to the following link on your browser:\r\n\r\n    ```\r\n    http://localhost:5002/docs\r\n    ```\r\n\r\n    This will take you to an UI like below:\r\n\r\n    ![Screenshot from 2020-06-21 22-15-18][screenshot_1]\r\n\r\n-   Press the `authorize` button on the right and add _username_ and _password_. The APIs\r\n    use OAuth2 (with hashed password and Bearer with JWT) based authentication. In this\r\n    case, the username and password is `ubuntu` and `debian` respectively.\r\n\r\n    ![Screenshot from 2020-06-21 22-18-25][screenshot_2]\r\n\r\n    Clicking the `authorize` button will bring up a screen like this:\r\n\r\n    ![Screenshot from 2020-06-21 22-18-59][screenshot_3]\r\n\r\n-   Then select any of the `api_a` or `api_b` APIs and put an integer in the number box and\r\n    click the `authorize` button.\r\n\r\n    ![Screenshot from 2020-06-21 22-31-19][screenshot_4]\r\n\r\n-   Hitting the API should give a json response with random integers.\r\n\r\n    ![Screenshot from 2020-06-21 22-32-28][screenshot_5]\r\n\r\n-   Also, notice the `curl` section in the above screen shot. You can directly use the\r\n    highlighted curl command in your terminal. Make sure you've got `jq` installed in your\r\n    system.\r\n\r\n    ```sh\r\n    curl -X GET \"http://localhost:5002/api_a/22\" \\\r\n            -H \"accept: application/json\" \\\r\n            -H \"Authorization: Bearer $(curl -X POST \"http://localhost:5002/token\" \\\r\n                            -H \"accept: application/x-www-form-urlencoded\" \\\r\n                            -d \"username=ubuntu&password=debian\" | jq -r \".access_token\")\"\r\n    ```\r\n\r\n    This should show a response like this:\r\n\r\n    ```json\r\n    {\r\n        \"seed\": 22,\r\n        \"random_first\": 5,\r\n        \"random_second\": 13\r\n    }\r\n    ```\r\n\r\n-   To test the `GET` APIs with Python, you can use a http client library like\r\n    [httpx][httpx]:\r\n\r\n    ```python\r\n    import httpx\r\n\r\n    with httpx.Client() as client:\r\n\r\n        # Collect the API token.\r\n        r = client.post(\r\n            \"http://localhost:5002/token\",\r\n            headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\r\n            data={\"username\": \"ubuntu\", \"password\": \"debian\"},\r\n        )\r\n        token = r.json()[\"access_token\"]\r\n\r\n        # Use the token value to hit the API.\r\n        r = client.get(\r\n            \"http://localhost:5002/api_a/22\",\r\n            headers={\"Accept\": \"application/json\", \"Authorization\": f\"Bearer {token}\"},\r\n        )\r\n        print(r.json())\r\n    ```\r\n\r\n## Folder structure\r\n\r\nThis shows the folder structure of the default template.\r\n\r\n```txt\r\nfastapi-nano\r\n├── app                           # primary app folder\r\n│   ├── apis                      # this houses all the API packages\r\n│   │   ├── api_a                 # api_a package\r\n│   │   │   ├── __init__.py       # empty init file to make the api_a folder a package\r\n│   │   │   ├── mainmod.py        # main module of api_a package\r\n│   │   │   └── submod.py         # submodule of api_a package\r\n│   │   └── api_b                 # api_b package\r\n│   │       ├── __init__.py       # empty init file to make the api_b folder a package\r\n│   │       ├── mainmod.py        # main module of api_b package\r\n│   │       └── submod.py         # submodule of api_b package\r\n│   ├── core                      # this is where the configs live\r\n│   │   ├── auth.py               # authentication with OAuth2\r\n│   │   ├── config.py             # sample config file\r\n│   │   └── __init__.py           # empty init file to make the config folder a package\r\n│   ├── __init__.py               # empty init file to make the app folder a package\r\n│   ├── main.py                   # main file where the fastAPI() class is called\r\n│   ├── routes                    # this is where all the routes live\r\n│   │   └── views.py              # file containing the endpoints of api_a and api_b\r\n│   └── tests                     # test package\r\n│       ├── __init__.py           # empty init file to make the tests folder a package\r\n│       ├── test_api.py           # integration testing the API responses\r\n│       └── test_functions.py     # unit testing the underlying functions\r\n├── dockerfiles                   # directory containing all the dockerfiles\r\n├── .env                          # env file containing app variables\r\n├── Caddyfile                     # simple reverse-proxy with caddy\r\n├── docker-compose.yml            # docker-compose file\r\n├── pyproject.toml                # pep-518 compliant config file\r\n├── requrements-dev.in            # .in file to enlist the top-level dev requirements\r\n├── requirements-dev.txt          # pinned dev dependencies\r\n├── requirements.in               # .in file to enlist the top-level app dependencies\r\n└── requirements.txt              # pinned app dependencies\r\n```\r\n\r\nIn the above structure, `api_a` and `api_b` are the main packages where the code of the APIs\r\nlive and they are exposed by the endpoints defined in the `routes` folder. Here, `api_a` and\r\n`api_b` have identical logic. Basically these are dummy APIs that take an integer as input\r\nand return two random integers between zero and the input value. The purpose of including\r\ntwo identical APIs in the template is to demonstrate how you can decouple the logics of\r\nmultiple APIs and then assemble their endpoints in the routes directory. The following\r\nsnippets show the logic behind the dummy APIs.\r\n\r\nThis is a dummy submodule that houses a function called `random_gen` which generates a\r\ndictionary of random integers.\r\n\r\n```python\r\n# This a dummy module\r\n# This gets called in the module_main.py file\r\nfrom __future__ import annotations\r\nimport random\r\n\r\n\r\ndef rand_gen(num: int) -> dict[str, int]:\r\n    num = int(num)\r\n    d = {\r\n        \"seed\": num,\r\n        \"random_first\": random.randint(0, num),\r\n        \"random_second\": random.randint(0, num),\r\n    }\r\n    return d\r\n```\r\n\r\nThe `main_func` in the primary module calls the `rand_gen` function from the submodule.\r\n\r\n```python\r\nfrom __future__ import annotations\r\nfrom app.api_a.submod import rand_gen\r\n\r\n\r\ndef main_func(num: int) -> dict[str, int]:\r\n    d = rand_gen(num)\r\n    return d\r\n```\r\n\r\nThe endpoint is exposed like this:\r\n\r\n```python\r\n# app/routes/views.py\r\nfrom __future__ import annotations\r\n#... codes regarding authentication ...\r\n\r\n# endpoint for api_a (api_b looks identical)\r\n@router.get(\"/api_a/{num}\", tags=[\"api_a\"])\r\nasync def view_a(num: int, auth: Depends =Depends(get_current_user)) -> dict[str, int]:\r\n    return main_func_a(num)\r\n```\r\n\r\nSo hitting the API with a random integer will give you a response like the following:\r\n\r\n```json\r\n{\r\n  \"seed\": 22,\r\n  \"random_first\": 27,\r\n  \"random_second\": 20\r\n}\r\n```\r\n\r\n## Further modifications\r\n\r\n-   You can put your own API logics in the shape of `api_a` and `api_b` packages. You'll\r\n    have to add additional directories like `api_a` and `api_b` if you need more APIs.\r\n\r\n-   Then expose the APIs in the `routes/views.py` file. You may choose to create multiple\r\n    `views` files to organize your endpoints.\r\n\r\n-   This template uses OAuth2 based authentication and it's easy to change that. FastAPI\r\n    docs has a comprehensive list of the available [authentication][fastapi_security]\r\n    options and instructions on how to use them.\r\n\r\n-   You can change the application port in the `.env` file.\r\n\r\n-   During prod deployment, you might need to fiddle with the reverse-proxy rules in the\r\n    Caddyfile.\r\n\r\n## Resources\r\n\r\n-   [Flask divisional folder structure][divisional_pattern]\r\n-   [Deploying APIs built with FastAPI](https://fastapi.tiangolo.com/deployment/)\r\n-   [Reverse proxying with Caddy](https://caddyserver.com/docs/caddyfile/directives/reverse_proxy)\r\n\r\n[caddy]: https://caddyserver.com/docs/\r\n[cors]: https://fastapi.tiangolo.com/tutorial/cors/\r\n[divisional_pattern]: https://exploreflask.com/en/latest/blueprints.html#divisional\r\n[docker]: https://www.docker.com/\r\n[fastapi]: https://fastapi.tiangolo.com/\r\n[fastapi_security]: https://fastapi.tiangolo.com/tutorial/security/\r\n[gunicorn]: https://gunicorn.org/\r\n[httpx]: https://www.python-httpx.org/\r\n[uvicorn]: https://uvicorn.org/\r\n[screenshot_1]:\r\n    https://user-images.githubusercontent.com/30027932/85229723-5b721880-b40d-11ea-8f03-de36c07a3ce5.png\r\n[screenshot_2]:\r\n    https://user-images.githubusercontent.com/30027932/85229725-5e6d0900-b40d-11ea-9c37-bbee546f84a8.png\r\n[screenshot_3]:\r\n    https://user-images.githubusercontent.com/30027932/85229729-6036cc80-b40d-11ea-877e-7421b927a849.png\r\n[screenshot_4]:\r\n    https://user-images.githubusercontent.com/30027932/85229992-fcad9e80-b40e-11ea-850d-9ca86259d463.png\r\n[screenshot_5]:\r\n    https://user-images.githubusercontent.com/30027932/85230016-25359880-b40f-11ea-9196-c46fd72a760c.png\r\n\r\n<div align=\"center\">\r\n✨ \uD83C\uDF70 ✨\r\n</div>\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/README.md b/README.md
--- a/README.md	(revision c06e1f6afdb5a3cce83b97029b24eb80bc4be5b2)
+++ b/README.md	(date 1727789802979)
@@ -245,8 +245,8 @@
 from __future__ import annotations
 #... codes regarding authentication ...
 
-# endpoint for api_a (api_b looks identical)
-@router.get("/api_a/{num}", tags=["api_a"])
+# endpoint for api_documents (api_llm looks identical)
+@router.get("/api_documents/{num}", tags=["api_documents"])
 async def view_a(num: int, auth: Depends =Depends(get_current_user)) -> dict[str, int]:
     return main_func_a(num)
 ```
Index: app/tests/test_functions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from unittest.mock import patch\r\n\r\nimport pytest\r\n\r\nfrom app.apis.api_a import mainmod as mainmod_a\r\nfrom app.apis.api_b import mainmod as mainmod_b\r\n\r\n\r\n@pytest.fixture(scope=\"module\")\r\ndef mock_randint():\r\n    \"\"\"Mock random.randint function.\"\"\"\r\n\r\n    with patch(\"random.randint\", return_value=42, auto=True) as m:\r\n        yield m\r\n\r\n\r\n@pytest.mark.parametrize(\r\n    (\"seed\", \"output\"),\r\n    [(1, 42), (100, 42), (589, 42), (444, 42)],\r\n)\r\ndef test_func_main_a(mock_randint, seed, output):\r\n    # Act.\r\n    result = mainmod_a.main_func(seed)\r\n\r\n    # Assert.\r\n    assert isinstance(result, dict) is True\r\n    assert result[\"seed\"] == seed\r\n    assert result[\"random_first\"] == output\r\n    assert result[\"random_second\"] == output\r\n\r\n    mock_randint.assert_called_with(0, seed)\r\n\r\n\r\n@pytest.mark.parametrize(\r\n    (\"seed\", \"output\"),\r\n    [(1, 42), (100, 42), (589, 42), (444, 42)],\r\n)\r\ndef test_func_main_b(mock_randint, seed, output):\r\n    # Act.\r\n    result = mainmod_b.main_func(seed)\r\n\r\n    # Assert.\r\n    assert isinstance(result, dict) is True\r\n    assert result[\"seed\"] == seed\r\n    assert result[\"random_first\"] == output\r\n    assert result[\"random_second\"] == output\r\n\r\n    mock_randint.assert_called_with(0, seed)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/tests/test_functions.py b/app/tests/test_functions.py
--- a/app/tests/test_functions.py	(revision c06e1f6afdb5a3cce83b97029b24eb80bc4be5b2)
+++ b/app/tests/test_functions.py	(date 1727789803011)
@@ -2,47 +2,47 @@
 
 import pytest
 
-from app.apis.api_a import mainmod as mainmod_a
-from app.apis.api_b import mainmod as mainmod_b
-
-
-@pytest.fixture(scope="module")
-def mock_randint():
-    """Mock random.randint function."""
-
-    with patch("random.randint", return_value=42, auto=True) as m:
-        yield m
-
-
-@pytest.mark.parametrize(
-    ("seed", "output"),
-    [(1, 42), (100, 42), (589, 42), (444, 42)],
-)
-def test_func_main_a(mock_randint, seed, output):
-    # Act.
-    result = mainmod_a.main_func(seed)
-
-    # Assert.
-    assert isinstance(result, dict) is True
-    assert result["seed"] == seed
-    assert result["random_first"] == output
-    assert result["random_second"] == output
-
-    mock_randint.assert_called_with(0, seed)
-
-
-@pytest.mark.parametrize(
-    ("seed", "output"),
-    [(1, 42), (100, 42), (589, 42), (444, 42)],
-)
-def test_func_main_b(mock_randint, seed, output):
-    # Act.
-    result = mainmod_b.main_func(seed)
-
-    # Assert.
-    assert isinstance(result, dict) is True
-    assert result["seed"] == seed
-    assert result["random_first"] == output
-    assert result["random_second"] == output
-
-    mock_randint.assert_called_with(0, seed)
+# from app.apis.api_documents import ProcessText as mainmod_a
+# from app.apis.api_llm import mainmod as mainmod_b
+#
+#
+# @pytest.fixture(scope="module")
+# def mock_randint():
+#     """Mock random.randint function."""
+#
+#     with patch("random.randint", return_value=42, auto=True) as m:
+#         yield m
+#
+#
+# @pytest.mark.parametrize(
+#     ("seed", "output"),
+#     [(1, 42), (100, 42), (589, 42), (444, 42)],
+# )
+# def test_func_main_a(mock_randint, seed, output):
+#     # Act.
+#     result = mainmod_a.main_func(seed)
+#
+#     # Assert.
+#     assert isinstance(result, dict) is True
+#     assert result["seed"] == seed
+#     assert result["random_first"] == output
+#     assert result["random_second"] == output
+#
+#     mock_randint.assert_called_with(0, seed)
+#
+#
+# @pytest.mark.parametrize(
+#     ("seed", "output"),
+#     [(1, 42), (100, 42), (589, 42), (444, 42)],
+# )
+# def test_func_main_b(mock_randint, seed, output):
+#     # Act.
+#     result = mainmod_b.main_func(seed)
+#
+#     # Assert.
+#     assert isinstance(result, dict) is True
+#     assert result["seed"] == seed
+#     assert result["random_first"] == output
+#     assert result["random_second"] == output
+#
+#     mock_randint.assert_called_with(0, seed)
Index: app/routes/views.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom fastapi import APIRouter, Depends\r\n\r\nfrom app.apis.api_a.mainmod import main_func as main_func_a\r\nfrom app.apis.api_b.mainmod import main_func as main_func_b\r\nfrom app.core.auth import get_current_user\r\n\r\nrouter = APIRouter()\r\n\r\n\r\n@router.get(\"/\")\r\nasync def index() -> dict[str, str]:\r\n    return {\r\n        \"info\": \"This is the index page of fastapi-nano. \"\r\n        \"You probably want to go to 'http://<hostname:port>/docs'.\",\r\n    }\r\n\r\n\r\n@router.get(\"/api_a/{num}\", tags=[\"api_a\"])\r\nasync def view_a(\r\n    num: int,\r\n    auth: Depends = Depends(get_current_user),\r\n) -> dict[str, int]:\r\n    return main_func_a(num)\r\n\r\n\r\n@router.get(\"/api_b/{num}\", tags=[\"api_b\"])\r\nasync def view_b(\r\n    num: int,\r\n    auth: Depends = Depends(get_current_user),\r\n) -> dict[str, int]:\r\n    return main_func_b(num)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/routes/views.py b/app/routes/views.py
--- a/app/routes/views.py	(revision c06e1f6afdb5a3cce83b97029b24eb80bc4be5b2)
+++ b/app/routes/views.py	(date 1727880389178)
@@ -1,33 +1,325 @@
 from __future__ import annotations
 
-from fastapi import APIRouter, Depends
+import json
+from typing import Optional, Dict, List, Annotated
+
+import requests
+from fastapi import APIRouter, Body, HTTPException
+from fastapi.responses import PlainTextResponse, RedirectResponse
+from haystack.components.builders import PromptBuilder
+from haystack_integrations.document_stores.elasticsearch import ElasticsearchDocumentStore
+from openai import OpenAI
+from pydantic import BaseModel, ConfigDict, model_validator, Field
+
+from app.apis.api_documents.utils import searchInDocstore, getContext
+from app.apis.api_llm.llm_utils import TEMPLATE_ASK
+from app.core.auth import decode_access_token
+from app.core.config import EMBEDDINGS_SERVER, DB_HOST, OLLAMA_SERVER, AUDIO_TRANSCRIBE_SERVER, LLM_MODEL
+
 
-from app.apis.api_a.mainmod import main_func as main_func_a
-from app.apis.api_b.mainmod import main_func as main_func_b
-from app.core.auth import get_current_user
+class FilterRequest(BaseModel):
+    model_config = ConfigDict(extra='forbid')
+    #filters: Optional[Dict[str, Union[PrimitiveType, List[PrimitiveType], Dict[str, PrimitiveType]]]] = None
+    filters: Optional[Dict] = None
+    token:str = Field(title="Access token", max_length=175)
+
+
+class InputParams(BaseModel):
+    model_config = ConfigDict(extra='forbid')
+    metadata: Optional[List[dict,]] = None
+
+    @model_validator(mode='before')
+    @classmethod
+    def validate_to_json(cls, value):
+        if isinstance(value, str):
+            return cls(**json.loads(value))
+        return value
+
+class SearchQueryParam(FilterRequest):
+    query:str = Field(title="Query max length 1500 chars", max_length=1500)
+    top_k:int = Field(default=5,gt=0, le=50, description="Number of search results")
+    context_size:int = Field(default=0,ge=0, le=20, description="Number of paragraphs in context")
 
 router = APIRouter()
 
+@router.get("/", include_in_schema=False)
+def main():
+    return RedirectResponse(url='/docs')
+
+@router.get("/status/", tags=["info"])
+def check_status():
+    result = {}
+    try:
+        res = requests.get(EMBEDDINGS_SERVER + "models/")
+        res.raise_for_status()
+        result.update({"embeddings_status": res.json()})
+    except requests.exceptions.RequestException as e:
+        result.update({"embeddings_status": "ERROR! " + str(e)})
+
+    try:
+        res = requests.get(DB_HOST + "/_cluster/health")
+        res.raise_for_status()
+        result.update({"db_status": res.json()})
+    except requests.exceptions.RequestException as e:
+        result.update({"db_status": "ERROR! " + str(e)})
+
+    try:
+        res = requests.get(OLLAMA_SERVER + "api/ps")
+        res.raise_for_status()
+        result.update({"llm_status": res.json()})
+    except requests.exceptions.RequestException as e:
+        result.update({"llm_status": "ERROR! " + str(e)})
+
+    try:
+        res = requests.get(AUDIO_TRANSCRIBE_SERVER + "status/")
+        res.raise_for_status()
+        result.update({"diarization_status": res.json()})
+    except requests.exceptions.RequestException as e:
+        result.update({"diarization_status": "ERROR! " + str(e)})
+
+    return result
+
+@router.post("/search/", tags=["search"])
+def search_document(params:Annotated[SearchQueryParam, Body(embed=True)]):
+    """
+    Receives the query as a string and allows the requester to set
+    additional parameters that will be passed on to the system to get a set of most relevant document pieces.
+    Depending on the context size, it return previous and later paragraphs from documents
+
+    Filter example:
+
+    To get all documents you should provide an empty dict, like:`'{"filters": {}}`
+
+    `{"filters": {"operator": "AND",
+                  "conditions": [
+                    {"field": "name", "operator": "==", "value": "2019"},
+                    {"field": "companies", "operator": "in", "value": ["BMW", "Mercedes"]}
+                          ]
+                   }
+                }`
+    """
+    index = decode_access_token(params.token)
+    print(index)
+    document_store = ElasticsearchDocumentStore(hosts=DB_HOST, index="semantic_search") #TODO: Replace index
+    docs = searchInDocstore(params, document_store)
+
+    result = []
+    if docs is None:
+        return result
+
+    for doc in docs:
+        result.append(doc.to_dict())
+    docs_context = getContext(result, params.context_size, document_store)
+    document_store.client.close()
+    return docs_context
+
+@router.post("/ask/", tags=["search"])
+def ask_document(params:Annotated[SearchQueryParam, Body(embed=True)]):
+    """
+    Receives the question as a string and allows the requester to set
+    additional parameters that will be passed on to the system to get a set of most relevant answers.
+
+    Filter example:
+
+    To get all documents you should provide an empty dict, like:`'{"filters": {}}`
+
+    `{"filters": {"operator": "AND",
+                  "conditions": [
+                    {"field": "name", "operator": "==", "value": "2019"},
+                    {"field": "companies", "operator": "in", "value": ["BMW", "Mercedes"]}
+                          ]
+                   }
+                }`
+    """
+    index = decode_access_token(params.token)
+    print(index)
+    document_store = ElasticsearchDocumentStore(hosts=DB_HOST, index="semantic_search")  # TODO: Replace index
+
+    myDocs = searchInDocstore(params, document_store)
+    if myDocs is None:
+        return {"answer": "None", "document": []}
+
+    #TODO get context, and exclude repeated paragraphs
+    grouped_docs = {}
+    for doc in myDocs:
+        name = doc.meta["name"]
+        doc.content = doc.content.replace('\r\n', '')
+        # Si el nombre no está en el diccionario, lo agrega con un contenido vacío
+        if name not in grouped_docs:
+            grouped_docs[name] = []
+        # Agrega el contenido al arreglo correspondiente al nombre
+        grouped_docs[name].append(doc.content)
+
+    builder = PromptBuilder(template=TEMPLATE_ASK)
+    my_prompt = builder.run(myDocs=grouped_docs, query=params.query.strip())["prompt"].strip()
+    # options ={"num_predict": -1,"temperature": 0.1}
+    client = OpenAI(base_url=OLLAMA_SERVER + 'v1/', api_key='ollama', )
+    completion = client.completions.create(
+        model=LLM_MODEL,
+        prompt=my_prompt,
+        temperature=0.1,
+        stream=False
+    )
+    # #response=launchAgent(my_prompt, options)
+    # if response is None:
+    #     response = ""
+    result = []
+    for doc in myDocs:
+        result.append(doc.to_dict())
+    docs_context = getContext(result, params.context_size, document_store)
+    final_result = {"answer":completion.choices[0].text, "document":docs_context}
+    document_store.client.close()
+    return final_result
+
+
+@router.post("/documents/get/", tags=["documents"])
+def get_documents(filters: FilterRequest):
+    """
+    Retrieve documents contained in your document store.
+    You can filter the documents to retrieve by metadata (like the document's name),
+    or provide an empty JSON object to clear the document store.
+
+    Filter example:
+
+    To get all documents you should provide an empty dict, like:`'{"filters": {}}`
 
-@router.get("/")
-async def index() -> dict[str, str]:
-    return {
-        "info": "This is the index page of fastapi-nano. "
-        "You probably want to go to 'http://<hostname:port>/docs'.",
-    }
+    `{"filters": {"operator": "AND",
+      			"conditions": [
+        			{"field": "name", "operator": "==", "value": "2019"},
+        			{"field": "companies", "operator": "in", "value": ["BMW", "Mercedes"]}
+      					]
+    			   }
+  		      }`
+    """
+    index = decode_access_token(filters.token)
+    print(index)
+    document_store = ElasticsearchDocumentStore(hosts=DB_HOST, index="semantic_search")  # TODO: Replace index
+
+    prediction = document_store.filter_documents(filters=filters.filters)
+    result = []
+    for doc in prediction:
+        doc_dict = doc.to_dict()
+        del doc_dict["embedding"]
+        result.append(doc_dict)
 
+    # print_documents(prediction, max_text_len=100, print_name=True, print_meta=True)
+    document_store.client.close()
+    return result
 
-@router.get("/api_a/{num}", tags=["api_a"])
-async def view_a(
-    num: int,
-    auth: Depends = Depends(get_current_user),
-) -> dict[str, int]:
-    return main_func_a(num)
 
+@router.post("/documents/name_list/", tags=["documents"])
+def list_documents_name(filters: FilterRequest):
+    """
+       Retrieve the filename of all documents loaded.
+       You can filter the documents to retrieve by metadata (like the document's name),
+       or provide an empty JSON object to clear the document store.
 
-@router.get("/api_b/{num}", tags=["api_b"])
-async def view_b(
-    num: int,
-    auth: Depends = Depends(get_current_user),
-) -> dict[str, int]:
-    return main_func_b(num)
+       Filter example:
+
+       To get all documents you should provide an empty dict, like:`'{"filters": {}}`
+
+       `{"filters": {"operator": "AND",
+                   "conditions": [
+                       {"field": "name", "operator": "==", "value": "2019"},
+                       {"field": "companies", "operator": "in", "value": ["BMW", "Mercedes"]}
+                           ]
+                      }
+                 }`
+   """
+    index = decode_access_token(filters.token)
+    print(index)
+    document_store = ElasticsearchDocumentStore(hosts=DB_HOST, index="semantic_search")  # TODO: Replace index
+    # print(filters.filters)
+    prediction = document_store.filter_documents(filters=filters.filters)
+
+    res = []
+    for doc in prediction:
+        res.append(doc.meta["name"])
+    res = list(set(res))
+    document_store.client.close()
+    return res
+
+
+@router.post("/documents/delete/", tags=["documents"])
+def delete_documents(filters: FilterRequest):
+    """
+    Delete documents contained in your document store.
+    You can filter the documents to delete by metadata (like the document's name),
+    or provide an empty JSON object to clear the document store.
+
+    Filter example:
+
+    To get all documents you should provide an empty dict, like:`'{"filters": {}}`
+
+    `{"filters": {"operator": "AND",
+      			"conditions": [
+        			{"field": "name", "operator": "==", "value": "2019"},
+        			{"field": "companies", "operator": "in", "value": ["BMW", "Mercedes"]}
+      					]
+    			   }
+  		      }`
+    """
+    index = decode_access_token(filters.token)
+    print(index)
+    document_store = ElasticsearchDocumentStore(hosts=DB_HOST, index="semantic_search")  # TODO: Replace index
+    prediction = document_store.filter_documents(filters=filters.filters)
+    ids = [doc.id for doc in prediction]
+    document_store.delete_documents(document_ids=ids)
+    document_store.client.close()
+    return True
+# @router.get("/api_documents/{num}", tags=["api_documents"])
+# async def view_a(
+#     num: int,
+#     #auth: Depends = Depends(get_current_project),
+#     token:str
+# ) -> str:
+#     #return main_func_a(num)
+#     return decode_access_token(token)
+
+@router.get("/audio/get_SRT/{token}/{file_name}/", tags=["audio"], response_class=PlainTextResponse)
+def get_SRT(file_name: str, token:str):
+    """
+    Get the srt file referred to a specific audio file that was processed previously.
+    """
+
+    index = decode_access_token(token)
+    print(index)
+    document_store = ElasticsearchDocumentStore(hosts=DB_HOST, index="semantic_search")  # TODO: Replace index
+    filters = {"field": "name", "operator": "==", "value": file_name.strip()}
+    prediction = document_store.filter_documents(filters=filters)
+    if len(prediction) > 0:
+        orderedlist = sorted(prediction, key=lambda d: d.meta['paragraph']) #order by paragraph
+        srt_file = ""
+        for i, doc in enumerate(orderedlist, start=1):
+            if doc.meta["file_type"].startswith("audio/"):
+                srt_file += f"{i}\n"
+                text1=f"{doc.meta['start_time']} --> {doc.meta['end_time']}\n"
+                srt_file += text1
+                text1 = f"{doc.meta['speaker']}: {doc.content}\n\n"
+                srt_file += text1
+        return srt_file
+    else:
+        raise HTTPException(status_code=404, detail="File not found!")
+
+
+@router.get("/status/{token}/{audio_file}/", tags=["audio"])
+async def get_audio_status(audio_file: str, token:str) -> dict:
+    '''
+    Show status of a file audio in the transcription batch processing.
+    * audio_file is the current audio that may be in process
+    '''
+    index = decode_access_token(token)
+    print(index)
+    result = {
+        "audio_file": audio_file,
+        "status": "ERROR!"
+    }
+
+    try:
+        res = requests.get(AUDIO_TRANSCRIBE_SERVER + "status/" + audio_file)
+        res.raise_for_status()
+        result = res.json()
+    except requests.exceptions.RequestException as e:
+        result.update({"status": "ERROR! " + str(e)})
+
+    return result
\ No newline at end of file
diff --git a/app/apis/api_a/__init__.py b/app/apis/api_documents/__init__.py
rename from app/apis/api_a/__init__.py
rename to app/apis/api_documents/__init__.py
diff --git a/app/apis/api_b/__init__.py b/app/apis/api_llm/__init__.py
rename from app/apis/api_b/__init__.py
rename to app/apis/api_llm/__init__.py
